## Gu铆a R谩pida de Open WebUI 

**Open WebUI** es una plataforma de interfaz de usuario de IA autoalojada, extensible y f谩cil de usar, que puede funcionar completamente sin conexi贸n. Permite interactuar con diferentes modelos de lenguaje (LLMs) y facilita la integraci贸n de diversas APIs compatibles como Ollama y OpenAI.

### Funcionalidades Principales

- **Instalaci贸n sencilla:** Compatible con Docker, Kubernetes y pip (Python).
- **Compatibilidad amplia:** Soporta Ollama, APIs tipo OpenAI, integraci贸n f谩cil con LMStudio, GroqCloud, Mistral, OpenRouter y m谩s.
- **Control de usuarios y permisos:** Roles y permisos granulados, con seguridad reforzada y experiencias personalizadas.
- **App web responsive y PWA:** Experiencia fluida en escritorio y m贸vil, incluso como aplicaci贸n web progresiva con acceso offline.
- **Soporte Markdown y LaTeX:** Ideal para respuestas ricas en formato y matem谩ticas.
- **Llamadas de voz/video integradas**, generaci贸n de im谩genes, integraci贸n nativa de Python y editor de c贸digo.
- **RAG local:** Soporta Retrieval Augmented Generation, permitiendo cargar archivos y hacer consultas avanzadas.
- **B煤squeda web:** Integra motores como SearXNG, Google, Brave, DuckDuckGo, Bing, entre otros.
- **Multilenguaje e internacionalizaci贸n:** Interfaz disponible en varios idiomas.
- **Actualizaci贸n continua y soporte comunitario.**

### Instalaci贸n R谩pida

#### Opci贸n 1: Python pip

1. Aseg煤rate de usar **Python 3.11**.
2. Instala con pip:

   ```bash
   pip install open-webui
   ```
3. Ejecuta el servidor:

   ```bash
   open-webui serve
   ```
4. Accede a la interfaz en [http://localhost:8080](http://localhost:8080).

#### Opci贸n 2: Docker (Recomendado)

- Si tienes Ollama en tu equipo:
   ```bash
   docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
   ```

- Para usar Open WebUI + Ollama todo en uno (con GPU):
   ```bash
   docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
   ```

- Para conexi贸n remota con Ollama, agrega la variable de entorno:
   ```bash
   docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://direccion-servidor -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
   ```

- Solo para OpenAI API:
   ```bash
   docker run -d -p 3000:8080 -e OPENAI_API_KEY=tu_clave_api -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
   ```

**Acceso:** Despu茅s de la instalaci贸n, ve a [http://localhost:3000](http://localhost:3000).

### Recomendaciones y Consejos

- **Montaje de volumen (-v):** Imprescindible para evitar p茅rdida de base de datos.
- **GPU:** Usa im谩genes `:cuda` si deseas aceleraci贸n por GPU en Linux/WSL (instala CUDA toolkit).
- **Actualizaci贸n:** Utiliza Watchtower para mantener tu contenedor Docker al d铆a.
- **Modo offline:** Define `HF_HUB_OFFLINE=1` si trabajas sin Internet.

### Recursos y Soporte

- **Documentaci贸n**: Revisa la documentaci贸n de Open WebUI para temas avanzados de configuraci贸n, integraci贸n y desarrollo.
- **Comunidad y ayuda:** nete a su Discord para soporte directo o abre un issue en GitHub.
- **Licencia:** BSD-3-Clause modificada (se debe mantener el branding de "Open WebUI").

### Resumen Visual

| Instalaci贸n      | Comando principal                                                                                |
|------------------|-------------------------------------------------------------------------------------------------|
| Python/pip       | `pip install open-webui` / `open-webui serve`                                                   |
| Docker + Ollama  | `docker run ... ghcr.io/open-webui/open-webui:ollama`                                           |
| Solo OpenAI API  | `docker run ... -e OPENAI_API_KEY=... ghcr.io/open-webui/open-webui:main`                       |
| Acceso           | http://localhost:3000 o http://localhost:8080 seg煤n instalaci贸n                                 |

**Open WebUI** es ideal para quienes buscan una soluci贸n robusta, autoalojada y con control total sobre su infraestructura de IA, listas para despliegue corporativo o entornos experimentales avanzados.

- https://github.com/open-webui/open-webui
- https://4geeks.com/es/interactive-coding-tutorial/instalando-ollama-y-openwebui